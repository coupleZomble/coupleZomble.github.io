<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>CoupleZomble&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="CoupleZomble&#39;s Blog">
<meta property="og:type" content="website">
<meta property="og:title" content="CoupleZomble&#39;s Blog">
<meta property="og:url" content="https://couplezomble.github.io/index.html">
<meta property="og:site_name" content="CoupleZomble&#39;s Blog">
<meta property="og:description" content="CoupleZomble&#39;s Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="cpz">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="CoupleZomble's Blog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">CoupleZomble&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">一个课程项目的展示</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS 订阅"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="搜索"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://coupleZomble.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="[layout]-LLM" class="h-entry article article-type-[layout]" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/12/24/LLM/" class="article-date">
  <time class="dt-published" datetime="2023-12-24T11:15:37.000Z" itemprop="datePublished">2023-12-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/12/24/LLM/">Base Konwledge of Domain-Specific LLMs</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="1-What-is-a-domain-specific-LLM"><a href="#1-What-is-a-domain-specific-LLM" class="headerlink" title="1. What is a domain-specific LLM"></a>1. What is a domain-specific LLM</h2><p>Domain-specific LLM指的是经过训练或微调，能够在组织指导下执行特定任务的通用模型。与通用语言模型不同，领域特定的LLM在实际应用中有着明确定义的目标。这样的定制模型需要深刻理解其上下文，包括产品数据、企业政策和行业术语。</p>
<p>foundational model和Domain-specific model之间的一个主要区别在于它们的训练过程。机器学习团队会使用自监督学习方法在未标注的数据集上训练基础模型。而在开发领域特定语言模型时，他们会通过监督学习精心筛选和标记训练样本。</p>
<h2 id="2-Why-build-a-domain-specific-LLM"><a href="#2-Why-build-a-domain-specific-LLM" class="headerlink" title="2. Why build a domain-specific LLM?"></a>2. Why build a domain-specific LLM?</h2><p>一般的LLM因其可扩展性和对话行为而备受赞誉。每个人都可以与通用语言模型进行交互，并获得类似人类的回应。几年前，这样的进步对公众来说还是难以想象的，但最近却成为现实。</p>
<p>然而，尽管基础模型具有自然语言处理能力，但它们远非完美。用户很快发现，当触发ChatGPT时，它可能产生幻觉并提供不准确的事实。例如，一名律师在法庭上使用聊天机器人进行研究，却提交了虚假案例。</p>
<h2 id="3-Examples-of-Domain-Specific-LLMs"><a href="#3-Examples-of-Domain-Specific-LLMs" class="headerlink" title="3. Examples of Domain-Specific LLMs"></a>3. Examples of Domain-Specific LLMs</h2><h5 id="1-Med-PaLM-2"><a href="#1-Med-PaLM-2" class="headerlink" title="1. Med-PaLM 2"></a><a target="_blank" rel="noopener" href="https://sites.research.google/med-palm/">1. Med-PaLM 2</a></h5><p>Med-PaLM 2是由谷歌构建的定制语言模型，通过对精心策划的医学数据集进行训练而生成。该模型可以准确回答医学问题，在某些应用场景中与医学专业人员不相上下。在测试中，MedPalm 2在包含美国医学执业考试问题的MedQA数据集上取得了86.5%的分数。</p>
<h5 id="2-ChatLAW"><a href="#2-ChatLAW" class="headerlink" title="2. ChatLAW"></a><a target="_blank" rel="noopener" href="https://github.com/PKU-YuanGroup/ChatLaw">2. ChatLAW</a></h5><p>ChatLAW是一个开源的语言模型，专门使用中国法律领域的数据集进行训练。该模型具有多项改进，包括一种特殊的方法，可以减少幻觉并提高推理能力。</p>
<h5 id="3-FinGPT"><a href="#3-FinGPT" class="headerlink" title="3. FinGPT"></a><a target="_blank" rel="noopener" href="https://github.com/AI4Finance-Foundation/FinGPT">3. FinGPT</a></h5><p>FinGPT是一个轻量级语言模型，使用金融数据进行预训练。与专有的BloombergGPT相比，它提供了更为经济实惠的训练选择。FinGPT还结合了RLHF，以实现进一步的个性化。在多个金融情感分析数据集上，FinGPT的得分表现非常出色，超过了其他几个模型。</p>
<h2 id="4-How-to-Create-a-Domain-specific-LLM"><a href="#4-How-to-Create-a-Domain-specific-LLM" class="headerlink" title="4. How to Create a Domain-specific LLM"></a>4. How to Create a Domain-specific LLM</h2><p>Domain-specific LLM 在逐渐成为推动各个领域产生积极变革的答案。行业领先者已经将基础模型重新用于特定的应用案例。问题是如何构建一个根据你需求定制的大型语言模型？</p>
<p>当谈到训练特定领域的模型时，并非所有组织都认为从头开始训练是可行的。在大多数情况下，对基础模型进行微调就足以以合理的准确性执行特定任务。这种方法需要较少的数据集、计算和时间。</p>
<h3 id="4-1-Fine-tune-an-LLM-for-domain-specific-needs"><a href="#4-1-Fine-tune-an-LLM-for-domain-specific-needs" class="headerlink" title="4.1 Fine-tune an LLM for domain-specific needs"></a>4.1 Fine-tune an LLM for domain-specific needs</h3><p>当微调一个大型语言模型（LLM）时，机器学习工程师使用预先训练好的模型，如GPT和LLaMa，这些模型已经具有出色的语言能力。他们通过使用一个小型的标注数据集以较慢的学习速率来训练模型的权重。微调的原理是在保留模型最初学到的知识的同时，让模型<br>适应新数据呈现的知识。它还涉及应用强大的内容审核机制，以避免模型生成有害内容。</p>
<h4 id="Transfer-learning"><a href="#Transfer-learning" class="headerlink" title="Transfer learning"></a>Transfer learning</h4><p><img src="/2023/12/24/LLM/transfer_Learning.jpg" alt="transfer_Learning"></p>
<p>迁移学习是一种独特的技术，允许预训练模型将其知识应用于新任务。当无法收集足够的数据集来微调模型时，这种技术非常有用。在进行迁移学习时，机器学习工程师会冻结模型的现有层，并在顶部添加新的可训练层。</p>
<p>MedPaLM是一个采用这种方法训练的领域特定模型的示例。它是建立在PaLM之上的，PaLM是一个拥有5400亿参数的语言模型，在复杂任务中表现出色。为了开发MedPaLM，谷歌使用了几种提示策略，向模型呈现了医学问题和答案的注释对。</p>
<p>仅使用65对对话样本，谷歌就产生了一个医学专用模型，该模型在回答HealthSearchQA问题时得分合格，并且在性能上远远超过了类似模型。谷歌的方法与常规做法有所不同，常规做法是向预训练模型提供多样化的领域特定数据。</p>
<p>虽然仍有改进空间，但谷歌的MedPalm及其后续版本MedPalm 2表明了利用创造性和成本效益的方法，对于特定任务优化LLM的可能性。</p>
<h4 id="Retrieval-augmented-generation"><a href="#Retrieval-augmented-generation" class="headerlink" title="Retrieval-augmented generation"></a>Retrieval-augmented generation</h4><p><img src="/2023/12/24/LLM/re.jpg" alt="Retrieval-augmented"></p>
<p>Retrieval-augmented generation (RAG) 是一种方法，结合了预训练模型和信息检索系统的优势。这种方法利用嵌入（Embeddings）使语言模型能够执行特定上下文任务，比如问答。嵌入是文本数据的数值表示，使得可以通过编程方式查询和检索文本数据。</p>
<p>当实施时，模型可以从数据仓库中提取特定领域的知识，并用这些知识生成有用的回应。这在部署需要实时信息或特定行业背景的自定义模型的应用中非常有用。例如，金融机构可以应用RAG，使特定领域的模型能够生成具有实时市场趋势的报告。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://couplezomble.github.io/2023/12/24/LLM/" data-id="clqjgo5fi0000u0cybkr7g3vd" data-title="Base Konwledge of Domain-Specific LLMs" class="article-share-link"><span class="fa fa-share">分享</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">十二月 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/12/24/LLM/">Base Konwledge of Domain-Specific LLMs</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 cpz<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>